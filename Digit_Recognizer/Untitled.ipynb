{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readign traingng set\n",
      "read all\n",
      "the number of dataset that read is 0\n",
      "the number of dataset that read is 1000\n",
      "the number of dataset that read is 2000\n",
      "the number of dataset that read is 3000\n",
      "the number of dataset that read is 4000\n",
      "the number of dataset that read is 5000\n",
      "the number of dataset that read is 6000\n",
      "the number of dataset that read is 7000\n",
      "the number of dataset that read is 8000\n",
      "the number of dataset that read is 9000\n",
      "the number of dataset that read is 10000\n",
      "the number of dataset that read is 11000\n",
      "the number of dataset that read is 12000\n",
      "the number of dataset that read is 13000\n",
      "the number of dataset that read is 14000\n",
      "the number of dataset that read is 15000\n",
      "the number of dataset that read is 16000\n",
      "the number of dataset that read is 17000\n",
      "the number of dataset that read is 18000\n",
      "the number of dataset that read is 19000\n",
      "the number of dataset that read is 20000\n",
      "the number of dataset that read is 21000\n",
      "the number of dataset that read is 22000\n",
      "the number of dataset that read is 23000\n",
      "the number of dataset that read is 24000\n",
      "the number of dataset that read is 25000\n",
      "the number of dataset that read is 26000\n",
      "the number of dataset that read is 27000\n",
      "the number of dataset that read is 28000\n",
      "the number of dataset that read is 29000\n",
      "the number of dataset that read is 30000\n",
      "the number of dataset that read is 31000\n",
      "the number of dataset that read is 32000\n",
      "the number of dataset that read is 33000\n",
      "the number of dataset that read is 34000\n",
      "the number of dataset that read is 35000\n",
      "the number of dataset that read is 36000\n",
      "the number of dataset that read is 37000\n",
      "the number of dataset that read is 38000\n",
      "the number of dataset that read is 39000\n",
      "the number of dataset that read is 40000\n",
      "the number of dataset that read is 41000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy import genfromtxt, savetxt\n",
    "import pandas as pd\n",
    "\n",
    "CPU = 6\n",
    "\n",
    "print \"Readign traingng set\"\n",
    "dataset = genfromtxt(open('train.csv', 'r'), delimiter=',', dtype='int64')[1:]\n",
    "print \"read all\"\n",
    "num_target=len(dataset)\n",
    "#target =  [x[0] for x in dataset]\n",
    "target =[]\n",
    "train = []\n",
    "for x in xrange(0, num_target):\n",
    "    target.append(dataset[x][0])\n",
    "    train.append(dataset[x][1:])\n",
    "    if (x % 1000 == 0):\n",
    "        print \"the number of dataset that read is %d\" %(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test set\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"Reading test set\"\n",
    "test = genfromtxt(open('test.csv', 'r'), delimiter=',', dtype = 'int64')[1:]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 1000, n_jobs=CPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RF classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=6,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Fitting RF classifier\"\n",
    "rf.fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test set\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"Predicting test set\"\n",
    "\n",
    "result = rf.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data={\"ImageId\": range(1, 28001), \"Label\":result})\n",
    "output.to_csv('submission-version-rf.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
